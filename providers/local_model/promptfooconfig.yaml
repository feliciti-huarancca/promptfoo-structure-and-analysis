description: Local model prompt configuration example

prompts:
  - 'Translate the following text to Spanish: "{{text_to_translate}}"'

providers:
  - id: openai:chat
    config:
      apiBaseUrl: http://127.0.0.1:1234/v1
      apiKey: lmstudio
      model: llama-3.2-1b-instruct
      temperature: 0.7
      max_tokens: 300

tests:
  - vars:
      text_to_translate: 'Hello, how are you?'
